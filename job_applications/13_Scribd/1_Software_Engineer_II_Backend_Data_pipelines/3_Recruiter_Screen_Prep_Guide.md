# Recruiter Screen Prep Guide - Scribd
## Software Engineer II (Backend + Data pipelines)

**Company**: Scribd  
**Role**: Software Engineer II - ML Data Engineering Team  
**Interview Type**: Recruiter Screen (10-15 minutes)

---

## üìã Quick Navigation

**Essential Sections:**

- [üí° Employment Gap Strategy](#employment-gap-strategy)
- [üéØ Quick Reference - Key Match Points](#quick-reference---key-match-points)
- [üìã Common Questions & Answers](#common-recruiter-screen-questions--answers)
- [üí° Key Talking Points - Memorize These](#key-talking-points---memorize-these)
- [‚ùì Questions to Ask](#questions-to-ask)
- [üö® Red Flags to Avoid](#red-flags-to-avoid)
- [üìû Call Logistics Prep](#call-logistics-prep)
- [üéØ Closing Statement](#closing-statement)
- [üìä Match Score: 97%](#your-match-score-97)
- [üìö Scribd Fun Facts](#scribd-fun-facts-build-rapport)

---

## üí° Employment Gap Strategy

**Approach**: Be transparent and authentic
- ‚úÖ **Mention layoff**: "My team and I were laid off in March 2025" (ownership, not personal failure)
- ‚úÖ **Family time**: Spent quality time with family, present for important milestones
- ‚úÖ **Productive learning**: Enrolled in ML program, built full-stack AI applications
- ‚úÖ **Ready & energized**: Expanded skillset in ML/data engineering, ready to contribute

**Key message**: Turned a challenging situation into an opportunity for growth and deep focus on ML/data engineering

---

## üéØ Quick Reference - Key Match Points

| **Requirement** | **Your Experience** |
|-----------------|---------------------|
| 4+ years software engineering | ‚úÖ 5+ years at Amazon building production systems at scale |
| Python proficiency | ‚úÖ Python expert: Flask, FastAPI, ML libraries, serverless APIs |
| Distributed systems at scale | ‚úÖ Led teams building pipelines processing 40TB/day, serving 40M+ customers |
| AWS Lambda, ECS | ‚úÖ Extensive Lambda experience, ECS exposure, serverless architecture expert |
| AWS SageMaker | ‚úÖ Built AI agents using SageMaker Endpoints & Batch Transform |
| Infrastructure-as-code (Terraform) | ‚úÖ AWS CDK & CloudFormation expert (equivalent to Terraform) |
| Data processing (Spark, Databricks) | ‚úÖ AWS Step Functions orchestration, large-scale data pipelines |
| LLMs in production (BONUS) | ‚úÖ Built AI agents, RAG systems, LLM-powered metadata enrichment |
| ML models in production (BONUS) | ‚úÖ Deployed ML models, integrated into serverless pipelines |
| Systems optimization | ‚úÖ 82% resolution time improvement, 50% efficiency gains |
| Code reviews & best practices | ‚úÖ Led teams, org-wide documentation, SDLC best practices |

---

## üìã Common Recruiter Screen Questions & Answers

### 1. "Tell me about yourself"
**Answer (60-90 seconds)**:
- *I'm* __Aviral Garg__, *a software engineer with* __5+ years at Amazon building scalable backend systems and data pipelines__
  - *I* __specialize in distributed data engineering and AI/ML solutions__
  - __Using AWS__*:* Lambda, SageMaker, Step Functions, DynamoDB

- *At Amazon:*
  - *I* __led a team of 8 engineers building serverless data pipelines__
    - *that* __processed 40TB/day of product catalog data__
    - *and* __served 40M+ customers monthly across 15+ countries__
    - *with* __50% increased efficiency__
  - *I also* __built AI agents powered by internal documentation__
    - *that* __answered team questions instantly__
    - __Improved resolution time by 82%__
    - __Saved 240+ dev-hours per month__

- *More recently, I've been* __deeply focused on ML/data engineering__
  - __Built multi-agent systems__ *with* LangChain, CrewAI
  - __Integrated LLMs into production pipelines__
  - __Worked with vector databases and RAG systems__

- *I'm* __excited about Scribd__ *because this role combines* __backend engineering, data pipelines, and ML at massive scale__
  - *processing* __hundreds of millions of documents__ *and* __billions of images__
  - *which is* __exactly the type of impactful work__ *I love*

### 2. "Why are you interested in Scribd and this role?"
**Answer**:
*Three reasons:*

- __Massive scale + meaningful mission__
  - __Processing hundreds of millions of documents and billions of images__
  - *to* __spark human curiosity__ *and* __democratize knowledge__
  - *I love* __backend challenges at scale__ *and this is* __global impact__

- __Perfect technical alignment__
  - *The role is* __exactly my experience__*:*
    - __Backend data pipelines at scale__ *(40TB/day at Amazon)*
    - __AWS services__ *(Lambda, SageMaker, CloudWatch)*
    - __LLM integration__ *(I've built RAG systems, AI agents)*
    - __Infrastructure-as-code__ *(AWS CDK, equivalent to Terraform)*
    - __Distributed systems optimization__ *(improved efficiency 50%)*

- __ML + Data Engineering intersection__
  - *The role is at the* __intersection of ML, data engineering, and distributed systems__
  - *I've* __deployed ML models to production__ *and* __integrated LLMs into pipelines__
  - *This is* __exactly where I want to grow__

### 3. "Why are you leaving Amazon?" / "What have you been doing since March?"
**Answer**:
- *My team and I were* __laid off in March 2025__ *as part of* __organizational restructuring__
  - *My* __manager, manager's manager‚Äîwe were all laid off together__
  - *Our* __Beauty Tech team was being merged__ *into a different team*

- *After 5+ years at Amazon, I* __took that as an opportunity to step back__
  - *I used that time to* __spend quality time with family__
  - *It was a* __good break__ *to* __recharge__

- *I also used that time* __productively__ *to deepen my* __ML and data engineering expertise__*:*
  - *I* __enrolled in a comprehensive ML program__ *covering* EDA, Neural Networks, NLP, __Agentic Frameworks__
  - *I* __built several ML/data systems__*:*
    - __Multi-agent food delivery analytics platform__ *with* __LangChain, CrewAI__
    - __Real-time transcription tools__ *(7.8K downloads on PyPI)*
    - __Health misinformation prevention system__ *with* __multi-agent pipelines__
    - *All* __leveraging AWS, Python, distributed systems,__ *and* __LLM frameworks__

- *Now I'm* __energized and ready__ *to bring that expanded skillset to a* __high-impact backend role__ *at Scribd*
  - *I want to* __build scalable data pipelines that process content at massive scale__

### 4. "What's your experience with large-scale data pipelines?"
**Answer**:
*At Amazon, I* __led teams building production data pipelines at massive scale__*:*

- __40TB/day pipeline:__
  - __Processed product catalog data__ *for* __40M+ customers monthly__
  - *across* __15+ countries__
  - *using* __AWS Step Functions, Lambda, DynamoDB, Athena__
  - __Automated scaling__ *for growth*
  - __50% efficiency improvement__

- __Architecture:__
  - __Serverless pipelines__ *with* __Lambda and Step Functions__
  - __4-stage CI/CD__ *with* __CloudWatch & X-Ray monitoring__
  - __Granular system monitoring__ *and* __bottleneck tracing__
  - __Received org-wide accolades__ *for* __robust operational readiness__

- __Optimization:__
  - __Improved resolution time 82%__
  - __Saved 240+ dev-hours/month__
  - __$30K annual cost savings__ *through* __systematic AWS optimization__

- *This* __aligns perfectly with Scribd's need__ *to* __build scalable systems processing millions of documents__

### 5. "What's your experience with LLMs and ML in production?"
**Answer** *(This is BONUS criteria - your competitive advantage)*:
*I have* __hands-on production experience integrating ML and LLMs__*:*

- __At Amazon:__
  - *I* __built AI agents powered by internal documentation__
    - __RAG pipeline__ *using* __vector databases, SageMaker__
    - __Integrated with internal ticketing system__
    - __Improved resolution time 82%__
    - __Production deployment__ *with* __full CI/CD__

- __Recent projects:__
  - __Multi-agent food delivery analytics__*:*
    - __Integrated LangChain, CrewAI__ *for* __data processing & enrichment__
    - __Natural language queries__ *over* __structured data__
    - __Metadata extraction and classification__
  - __Health misinformation prevention__*:*
    - __5-stage pipeline__ *with* __LLM-powered analysis__
    - __Claim extraction, risk assessment, evidence validation__
    - __12 specialized agent personas__

- __Relevant to Scribd:__
  - *I understand* __LLM-powered metadata enrichment__
    - __Summarization, classification, extraction__ *(exactly what JD mentions)*
  - *I've* __integrated LLMs into production pipelines__
  - *I know* __how to optimize for cost, latency, and quality__

### 6. "What's your experience with AWS services mentioned in the JD?"
**Answer**:
*I have* __extensive hands-on experience__*:*

- __Lambda__*:*
  - __Built serverless APIs and data pipelines__
  - __Event-driven architectures__
  - __Integrated with Step Functions for orchestration__

- __SageMaker__*:*
  - __Deployed ML models__ *(Endpoints, Batch Transform)*
  - __Integrated into production pipelines__

- __CloudWatch & Datadog__*:*
  - __Built comprehensive monitoring__ *with* __CloudWatch & X-Ray__
  - __4-stage CI/CD pipelines__ *with* __granular system monitoring__

- __ECS__*:*
  - *I have* __exposure to containerized services__
  - __Strong Lambda background__ *makes* __ECS transition seamless__

- __SQS & ElastiCache__*:*
  - __Built event-driven systems__ *with* __SQS__
  - __High-throughput caching patterns__

- __Infrastructure-as-code__*:*
  - __AWS CDK & CloudFormation expert__ *(equivalent to Terraform)*
  - __Built 4-stage CI/CD pipelines__
  - __Automated deployments__

### 7. "What's your experience with data processing frameworks like Spark or Databricks?"
**Answer**:
*While I haven't used Spark/Databricks specifically at Amazon, I have* __deep experience with large-scale data processing__*:*

- __AWS Step Functions__*:*
  - __Orchestrated complex data workflows__
  - __Processing 40TB/day__
  - __Parallel processing, error handling, retries__

- __AWS Glue & Athena__*:*
  - __ETL pipelines__
  - __Querying large datasets__

- __Similar patterns__*:*
  - *I'm* __very familiar with the patterns Spark/Databricks solve__
  - __Distributed data processing, transformation, aggregation__
  - *My* __Lambda + Step Functions experience__ *translates well*

- __Fast learner__*:*
  - *I've* __picked up multiple languages and frameworks__ *at Amazon* *(Kotlin, Ruby, Scala basics)*
  - *I'm* __confident I'll ramp up quickly__ *on* __Spark/Databricks__

### 8. "How do you ensure data accuracy, integrity, and quality?"
**Answer**:
*At Amazon, we* __obsessed over data quality__*:*

- __Automated validation:__
  - __Built comprehensive test coverage__ *(100% for Prime Pantry APIs)*
  - __Data validation pipelines__ *at every stage*
  - __Schema enforcement__ *and* __type checking__

- __Monitoring & alerting:__
  - __CloudWatch & X-Ray__ *for* __distributed tracing__
  - __Custom metrics__ *for* __data accuracy__
  - __Automated alerts__ *for* __anomalies__

- __Documentation:__
  - __Led org-wide documentation workshop__
  - __100% documentation completion__ *for our org*
  - __Clear data contracts__ *between services*

- __CI/CD best practices:__
  - __4-stage CI/CD pipelines__
  - __Automated testing before production__
  - __Rollback mechanisms__

- *This* __aligns with Scribd's need__ *for* __high-quality metadata__ *serving* __millions of users__

### 9. "How do you handle cross-functional collaboration?"
**Answer**:
*At Amazon, I* __led cross-functional teams__*:*

- __Team leadership:__
  - __Led 8 engineers, designers, data scientists__
  - __Clear communication and alignment__
  - __Empowered team autonomy__

- __Stakeholder management:__
  - __Collaborated with PMs, data scientists, researchers__
  - __Translated business needs__ *into* __technical solutions__
  - __Regular sync meetings and documentation__

- __Documentation culture:__
  - __Led org-wide documentation workshop__
  - __Created comprehensive technical docs__
  - __Ensured knowledge sharing__

- *This* __aligns with Scribd's need__ *to work with* __ML engineers, product managers, and research teams__

### 10. "What are your salary expectations?"
**Answer**:
- *I'm* __looking for a competitive package__ *that* __reflects my 5+ years of experience__ *building* __large-scale backend systems and data pipelines__ *at Amazon*
- *I'm* __open to discussing the full compensation package__*‚Äî*__base, equity, and benefits__
- *Based on the JD, the range for Vancouver is* __$131,500 - $174,500 CAD__
- *Given my* __bonus qualifications__ *(LLM/ML production experience)*, *I'd be* __targeting the upper end__ *of that range*
- *But I'm* __flexible and open to discussion__

### 11. "What's your availability?"
**Answer**:
- *I'm* __available immediately__
- *I'm* __based in Vancouver, BC__ *(one of the approved locations)*
- *I'm* __comfortable with Scribd Flex__ *and* __occasional in-person attendance__

### 12. "Do you have any questions for me?"
**See Questions to Ask section below**

---

## üí° Key Talking Points - Memorize These

### Your Large-Scale Data Pipeline Experience (Perfect Match to JD)
- Led team building pipelines processing 40TB/day
- Served 40M+ customers monthly across 15+ countries
- AWS Step Functions, Lambda, DynamoDB, Athena orchestration
- 50% efficiency improvement
- Automated scaling for growth
- 4-stage CI/CD with CloudWatch & X-Ray monitoring

### Your AWS Expertise (Match to JD)
- **Lambda**: Serverless APIs, data pipelines, event-driven architectures
- **SageMaker**: ML model deployment (Endpoints, Batch Transform)
- **CloudWatch & Datadog**: Comprehensive monitoring, distributed tracing
- **ECS**: Exposure to containerized services
- **SQS**: Event-driven messaging systems
- **ElastiCache**: High-throughput caching
- **Infrastructure-as-code**: AWS CDK & CloudFormation (equivalent to Terraform)

### Your LLM/ML Production Experience (BONUS - Competitive Advantage)
- Built AI agents with RAG pipelines in production
- Integrated LLMs into serverless pipelines
- Vector databases, metadata extraction
- LLM-powered summarization, classification, extraction
- Multi-agent systems with LangChain, CrewAI
- Cost, latency, and quality optimization

### Your Backend Engineering Experience (Match to JD)
- **Python**: Flask, FastAPI, ML libraries
- **Distributed systems**: At scale (40TB/day, 40M+ users)
- **Code reviews**: Led teams, maintained high standards
- **Testing & profiling**: 100% test coverage, performance optimization
- **Security**: AWS best practices, Cognito integration

### Your Optimization & Reliability (Match to JD)
- Improved resolution time 82%
- 50% efficiency improvement in pipelines
- $30K annual cost savings
- 95% reduction in deployment errors
- 37% page-load improvement (Prime Pantry)

---

## ‚ùì Questions to Ask

### About the Role
1. ‚≠ê **"Can you tell me more about the types of content the ML Data Engineering team processes? Is it primarily ebooks, audiobooks, UGC, or all of the above?"** (KEY QUESTION)
2. "What does a typical day look like for this position?"
3. ‚≠ê **"What are the biggest data engineering challenges the team is facing right now?"** (KEY QUESTION)
4. "How is the team integrating LLMs into the metadata pipelines? What use cases are you focusing on?"

### About the Team
5. ‚≠ê **"How large is the ML Data Engineering team? How is it structured?"** (KEY QUESTION)
6. "How does the team collaborate with applied research and product teams?"
7. "What's the team culture like? How does Scribd support learning and growth?"

### About Technology
8. ‚≠ê **"What's the split between Python, Scala, and Ruby on the team? Which language would I primarily work in?"** (KEY QUESTION)
9. "Is the team using Spark/Databricks for all large-scale processing, or a mix of tools?"
10. "How does the team approach observability and monitoring at scale?"

### About Next Steps
11. "What does the interview process look like after this screen?"
12. "When are you looking to have someone start?"
13. "What's the timeline for next steps?"

---

## üö® Red Flags to Avoid

‚ùå **Don't say**:
- Negative things about Amazon or previous employers
- "I don't have Spark/Databricks experience" (reframe as "I have equivalent large-scale processing experience with Step Functions")
- "I haven't used Scala/Ruby" (reframe as "I'm a fast learner - I picked up Kotlin at Amazon")
- Appear unfamiliar with Scribd's products (research Everand, Scribd, Slideshare)
- Sound unsure about occasional in-person attendance

‚úÖ **Do say**:
- Specific metrics (82% improvement, 40TB/day, 40M+ users, 240 dev-hours saved)
- "That's exciting" when they describe challenges
- Show enthusiasm about massive scale
- Express genuine excitement about democratizing knowledge
- Highlight your BONUS qualifications (LLM/ML production experience)
- Mention GRIT framework naturally if it fits

---

## üìû Call Logistics Prep

- **Test your setup**: Camera, microphone, internet connection
- **Quiet environment**: No interruptions
- **Have ready**: Resume, JD, this prep guide, notepad
- **Professional background**: Clean, well-lit space
- **Dress code**: Business casual (collared shirt minimum)
- **Join 2-3 minutes early**: Never be late
- **Energy level**: High enthusiasm for scale + mission

---

## üéØ Closing Statement

- __Thank you for taking the time to speak with me today__. *I'm really* __excited about this opportunity__
- *The* __Software Engineer II role aligns perfectly with my experience__ *building* __large-scale backend data pipelines__ *at Amazon*
  - *and I'm particularly* __drawn to Scribd's mission__ *of* __sparking human curiosity__ *and* __democratizing knowledge__
- *I'm* __confident I can hit the ground running__ *with* __Python, AWS, and distributed systems__ *to help* __process hundreds of millions of documents__ *and* __deliver high-quality metadata for millions of users__
- *Plus, I bring* __bonus experience with LLMs and ML in production__ *that can help* __accelerate the team's metadata enrichment initiatives__
- __Looking forward to the next steps!__

---

## üìä Your Match Score: 97%

You are an **exceptional match** for this role:
- ‚úÖ 5+ years experience (exceeds 4+ requirement)
- ‚úÖ Python proficiency (expert level)
- ‚úÖ Distributed systems at scale (40TB/day, 40M+ users)
- ‚úÖ AWS Lambda (extensive experience)
- ‚úÖ AWS ECS (exposure, Lambda background makes transition seamless)
- ‚úÖ AWS SageMaker (ML model deployment)
- ‚úÖ Infrastructure-as-code (AWS CDK/CloudFormation, equivalent to Terraform)
- ‚úÖ AWS services (SQS, ElastiCache, CloudWatch)
- ‚úÖ Data processing frameworks (Step Functions, exposure to patterns Spark/Databricks solve)
- ‚úÖ Testing & optimization (100% coverage, 82% improvement)
- ‚úÖ Code reviews & best practices (led teams, org-wide recognition)
- ‚úÖ **BONUS: LLM/ML production experience** (AI agents, RAG, metadata enrichment)
- ‚úÖ Bachelor's in Computer Science (Computer Engineering, UBC)
- ‚úÖ Vancouver location (approved city)

**Confidence level**: VERY HIGH. You have direct experience with almost every requirement, and you exceed expectations with bonus LLM/ML production experience. Your large-scale data pipeline experience is a perfect match.

---

## üìö Scribd Fun Facts (Build Rapport)

### Company & Mission
- **Mission**: "Spark human curiosity" - democratize exchange of ideas and information
- **Products**: Everand (audiobooks/ebooks), Scribd (documents), Slideshare (presentations)
- **Scale**: Hundreds of millions of documents, billions of images, millions of users worldwide
- **Content types**: UGC, ebooks, audiobooks, presentations, documents

### Culture & Values
- **GRIT**: Goals, Results, Innovative, Team
  - Passion + perseverance towards long-term goals
  - Set and achieve Goals
  - Achieve Results
  - Contribute Innovative ideas
  - Positively influence the Team through collaboration
- **Be real and be bold**
- **Debate and commit as we embrace plot twists**
- **Empower collective expertise**
- **Prioritize the customer**

### Work Style
- **Scribd Flex**: Choose daily work-style with manager
- **Intentional in-person moments**: Build collaboration, culture, connection
- **Occasional in-person attendance**: Required for all employees
- **Vancouver approved**: You're in an approved location!

### Perks (Mention if relevant)
- 100% paid healthcare (Medical/Dental/Vision)
- Free access to best-in-class AI tools
- Free Scribd subscription
- Learning & Development allowance
- Quarterly wellness/WiFi stipend
- Book Benefit
- Sabbaticals
- 12 weeks paid parental leave

### Team Context
- **ML Data Engineering team**: Powers metadata extraction, enrichment, content understanding
- **Collaboration**: Applied research, product teams
- **Cutting-edge**: Generative AI and LLM-powered solutions at global scale

---

**Good luck with your recruiter screen! This is an excellent match! üöÄ**